{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d668226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "\n",
    "import spacy\n",
    "from es_lemmatizer import lemmatize\n",
    "\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "from gensim import utils\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9b9ff4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_corpus = pd.read_csv(\"AnnotatedTweets.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2575d9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Another class show tonight #TommyTiernanShow U...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:57:06+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The county needs more people like Tommy and Br...</td>\n",
       "      <td>positive</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:55:45+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What age are ya????\\nHave you ever been examin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:47:26+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tommy was almost as good as Croker earlier #Go...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:46:54+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#TommyTiernanShow Brush Shields walks out and ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:46:12+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  polarity  \\\n",
       "1  Another class show tonight #TommyTiernanShow U...  positive   \n",
       "2  The county needs more people like Tommy and Br...  positive   \n",
       "3  What age are ya????\\nHave you ever been examin...  positive   \n",
       "4  Tommy was almost as good as Croker earlier #Go...  positive   \n",
       "5  #TommyTiernanShow Brush Shields walks out and ...   neutral   \n",
       "\n",
       "   favourite_count  retweet_count                 created_at  \n",
       "1                5              0  2022-02-12 23:57:06+00:00  \n",
       "2                6              0  2022-02-12 23:55:45+00:00  \n",
       "3                1              0  2022-02-12 23:47:26+00:00  \n",
       "4                1              0  2022-02-12 23:46:54+00:00  \n",
       "5                2              0  2022-02-12 23:46:12+00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccb6895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cat_columns(tweets_corpus, choices, name_res_column):\n",
    "    conditions = [\n",
    "        (tweets_corpus[\"polarity\"]  == 'positive'),\n",
    "        (tweets_corpus[\"polarity\"]  == 'neutral'),\n",
    "        (tweets_corpus[\"polarity\"]  == 'negative')]\n",
    "  #  tweets_corpus[name_res_column] = np.select(conditions, choices, default='NONE')\n",
    " #   tweets_corpus[name_res_column] = tweets_corpus[name_res_column].astype(int)\n",
    "    return tweets_corpus\n",
    "\n",
    "\n",
    "tweets_corpus = create_cat_columns(tweets_corpus=tweets_corpus,\n",
    "                                   choices=[1, 0, -1],\n",
    "                                   name_res_column= \"polarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6629b5a",
   "metadata": {},
   "source": [
    "Functions to clean tweets by removing stopwords etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3b2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_stop_words(list_new_stopwords, remove_words):\n",
    "    custom_stop_words = list(set(stopwords.words('english')))\n",
    "    custom_stop_words.extend(list_new_stopwords)\n",
    "    custom_stop_words = [word for word in custom_stop_words if word not in remove_words]\n",
    "    return custom_stop_words\n",
    "\n",
    "def lemmatizer(text):\n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "\n",
    "def clean_text(s):\n",
    "    filters = [gsp.strip_tags,\n",
    "               gsp.strip_punctuation,\n",
    "               gsp.strip_multiple_whitespaces,\n",
    "               gsp.strip_numeric]\n",
    "    s = re.sub(r'http\\S+', '', s)\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    s = utils.deaccent(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ece11b",
   "metadata": {},
   "source": [
    "Clean Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edbc1973",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_nltk = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nlp.add_pipe(lemmatize, after=\"tagger\")\n",
    "\n",
    "\n",
    "list_new_stopwords = [\"yet\", \"be\", \"watch\", \"today\", \"your\", \"here\",\n",
    "                              \"we go\", \"to have\", \"do\", \"have\", \"to go\",\n",
    "                              \"say\", \"eat\",\"so\", \"well\", \"latelateshow\",\"https\", \"tommy\"]\n",
    "remove_words = [\"no\", \"yes\", \"tommytiernanshow\"]\n",
    "\n",
    "custom_stop_words = create_custom_stop_words(list_new_stopwords, remove_words)\n",
    "\n",
    "tweets_corpus[\"content_clean\"] =  tweets_corpus[\"text\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (custom_stop_words)]))\n",
    "tweets_corpus[\"content_clean\"] = tweets_corpus[\"content_clean\"].apply(lambda x: clean_text(x))\n",
    "tweets_corpus = tweets_corpus.dropna(subset=[\"content_clean\"])\n",
    "tweets_corpus[\"content_clean\"] = tweets_corpus[\"content_clean\"].replace('\\s+', ' ', regex=True)\n",
    "tweets_corpus[\"content_clean\"] = tweets_corpus[\"content_clean\"].replace(\"\", np.nan)\n",
    "tweets_corpus[\"content_clean\"] = tweets_corpus[\"content_clean\"].replace(\" \", np.nan)\n",
    "tweets_corpus = tweets_corpus.dropna(subset=[\"content_clean\"])\n",
    "\n",
    "tweets_corpus = tweets_corpus[tweets_corpus['content_clean'].apply(lambda x: len(x) > 3)]\n",
    "tweets_corpus.dropna(subset=['content_clean'], inplace=True)\n",
    "tweets_corpus.reset_index(drop=True, inplace=True)\n",
    "\n",
    "tweets_corpus[\"lemma_clean_text\"] = tweets_corpus[\"content_clean\"].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b86dc37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>lemma_clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Another class show tonight #TommyTiernanShow U...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:57:06+00:00</td>\n",
       "      <td>another class show tonight tommytiernanshow un...</td>\n",
       "      <td>another class show tonight tommytiernanshow un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The county needs more people like Tommy and Br...</td>\n",
       "      <td>positive</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:55:45+00:00</td>\n",
       "      <td>the county needs people like tommy brush tommy...</td>\n",
       "      <td>the county need people like tommy brush tommyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What age are ya????\\nHave you ever been examin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:47:26+00:00</td>\n",
       "      <td>what age ya have ever examined simple question...</td>\n",
       "      <td>what age ya have ever examine simple question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tommy was almost as good as Croker earlier #Go...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:46:54+00:00</td>\n",
       "      <td>tommy almost good croker earlier goodsaturday ...</td>\n",
       "      <td>tommy almost good croker early goodsaturday to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#TommyTiernanShow Brush Shields walks out and ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:46:12+00:00</td>\n",
       "      <td>tommytiernanshow brush shields walks i self c...</td>\n",
       "      <td>tommytiernanshow brush shields walk i self c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  polarity  \\\n",
       "0  Another class show tonight #TommyTiernanShow U...  positive   \n",
       "1  The county needs more people like Tommy and Br...  positive   \n",
       "2  What age are ya????\\nHave you ever been examin...  positive   \n",
       "3  Tommy was almost as good as Croker earlier #Go...  positive   \n",
       "4  #TommyTiernanShow Brush Shields walks out and ...   neutral   \n",
       "\n",
       "   favourite_count  retweet_count                 created_at  \\\n",
       "0                5              0  2022-02-12 23:57:06+00:00   \n",
       "1                6              0  2022-02-12 23:55:45+00:00   \n",
       "2                1              0  2022-02-12 23:47:26+00:00   \n",
       "3                1              0  2022-02-12 23:46:54+00:00   \n",
       "4                2              0  2022-02-12 23:46:12+00:00   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  another class show tonight tommytiernanshow un...   \n",
       "1  the county needs people like tommy brush tommy...   \n",
       "2  what age ya have ever examined simple question...   \n",
       "3  tommy almost good croker earlier goodsaturday ...   \n",
       "4   tommytiernanshow brush shields walks i self c...   \n",
       "\n",
       "                                    lemma_clean_text  \n",
       "0  another class show tonight tommytiernanshow un...  \n",
       "1  the county need people like tommy brush tommyt...  \n",
       "2  what age ya have ever examine simple question ...  \n",
       "3  tommy almost good croker early goodsaturday to...  \n",
       "4    tommytiernanshow brush shields walk i self c...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7fa6ed",
   "metadata": {},
   "source": [
    "Show counts of positive, negative and neutral tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53adaa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    761\n",
       "negative    356\n",
       "neutral     347\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus[\"polarity\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556e6adc",
   "metadata": {},
   "source": [
    "Separate 5% of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72d79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate 5% of posts for final checkup\n",
    "msk = np.random.rand(len(tweets_corpus)) < 0.9\n",
    "test_corpus = tweets_corpus[~msk]\n",
    "tweets_corpus = tweets_corpus[msk]\n",
    "tweets_corpus.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9c6c1",
   "metadata": {},
   "source": [
    "functions for training and testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12af4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(train_fit, custom_stop_words):\n",
    "    vector = TfidfVectorizer(sublinear_tf=True, max_df=.9, stop_words=custom_stop_words)\n",
    "    vector.fit(train_fit)\n",
    "    return vector\n",
    "\n",
    "def create_train_test(tweets_corpus, col_name_label, col_name_text, custom_stop_words):\n",
    "    # Same tf vector will be used for Testing sentiments on unseen trending data\n",
    "    tf_vector = get_feature_vector(np.array(tweets_corpus.loc[:, col_name_text]).ravel(),\n",
    "                                   custom_stop_words)\n",
    "    X = tf_vector.transform(np.array(tweets_corpus.loc[:, col_name_text]).ravel())\n",
    "    y = np.array(tweets_corpus.loc[:, col_name_label]).ravel()\n",
    "    indices = list(tweets_corpus.index)\n",
    "    X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, indices, test_size=0.2, random_state=125)\n",
    "    return X_train, X_test, y_train, y_test, indices_train, indices_test, tf_vector\n",
    "\n",
    "def train_model(model_selected, X_train, X_test, y_train, y_test):\n",
    "    model = model_selected\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    print()\n",
    "    print(confusion_matrix(y_test, y_predict))\n",
    "    print()\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    return model, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112b263c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>lemma_clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Another class show tonight #TommyTiernanShow U...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:57:06+00:00</td>\n",
       "      <td>another class show tonight tommytiernanshow un...</td>\n",
       "      <td>another class show tonight tommytiernanshow un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The county needs more people like Tommy and Br...</td>\n",
       "      <td>positive</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:55:45+00:00</td>\n",
       "      <td>the county needs people like tommy brush tommy...</td>\n",
       "      <td>the county need people like tommy brush tommyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What age are ya????\\nHave you ever been examin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:47:26+00:00</td>\n",
       "      <td>what age ya have ever examined simple question...</td>\n",
       "      <td>what age ya have ever examine simple question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tommy was almost as good as Croker earlier #Go...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:46:54+00:00</td>\n",
       "      <td>tommy almost good croker earlier goodsaturday ...</td>\n",
       "      <td>tommy almost good croker early goodsaturday to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#TommyTiernanShow Brush Shields walks out and ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:46:12+00:00</td>\n",
       "      <td>tommytiernanshow brush shields walks i self c...</td>\n",
       "      <td>tommytiernanshow brush shields walk i self c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  polarity  \\\n",
       "0  Another class show tonight #TommyTiernanShow U...  positive   \n",
       "1  The county needs more people like Tommy and Br...  positive   \n",
       "2  What age are ya????\\nHave you ever been examin...  positive   \n",
       "3  Tommy was almost as good as Croker earlier #Go...  positive   \n",
       "4  #TommyTiernanShow Brush Shields walks out and ...   neutral   \n",
       "\n",
       "   favourite_count  retweet_count                 created_at  \\\n",
       "0                5              0  2022-02-12 23:57:06+00:00   \n",
       "1                6              0  2022-02-12 23:55:45+00:00   \n",
       "2                1              0  2022-02-12 23:47:26+00:00   \n",
       "3                1              0  2022-02-12 23:46:54+00:00   \n",
       "4                2              0  2022-02-12 23:46:12+00:00   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  another class show tonight tommytiernanshow un...   \n",
       "1  the county needs people like tommy brush tommy...   \n",
       "2  what age ya have ever examined simple question...   \n",
       "3  tommy almost good croker earlier goodsaturday ...   \n",
       "4   tommytiernanshow brush shields walks i self c...   \n",
       "\n",
       "                                    lemma_clean_text  \n",
       "0  another class show tonight tommytiernanshow un...  \n",
       "1  the county need people like tommy brush tommyt...  \n",
       "2  what age ya have ever examine simple question ...  \n",
       "3  tommy almost good croker early goodsaturday to...  \n",
       "4    tommytiernanshow brush shields walk i self c...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082bc813",
   "metadata": {},
   "source": [
    "Apply different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aa9a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fergalflattery/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['go'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 37  10  14]\n",
      " [ 14  25  25]\n",
      " [ 10  11 118]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.61      0.61        61\n",
      "     neutral       0.54      0.39      0.45        64\n",
      "    positive       0.75      0.85      0.80       139\n",
      "\n",
      "    accuracy                           0.68       264\n",
      "   macro avg       0.63      0.62      0.62       264\n",
      "weighted avg       0.67      0.68      0.67       264\n",
      "\n",
      "\n",
      "[[ 22   3  36]\n",
      " [  6  10  48]\n",
      " [  1   3 135]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.36      0.49        61\n",
      "     neutral       0.62      0.16      0.25        64\n",
      "    positive       0.62      0.97      0.75       139\n",
      "\n",
      "    accuracy                           0.63       264\n",
      "   macro avg       0.67      0.50      0.50       264\n",
      "weighted avg       0.65      0.63      0.57       264\n",
      "\n",
      "\n",
      "[[ 27   7  27]\n",
      " [  9  13  42]\n",
      " [  3   4 132]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.44      0.54        61\n",
      "     neutral       0.54      0.20      0.30        64\n",
      "    positive       0.66      0.95      0.78       139\n",
      "\n",
      "    accuracy                           0.65       264\n",
      "   macro avg       0.63      0.53      0.54       264\n",
      "weighted avg       0.64      0.65      0.61       264\n",
      "\n",
      "\n",
      "[[ 34   7  20]\n",
      " [  9  17  38]\n",
      " [  7   8 124]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.56      0.61        61\n",
      "     neutral       0.53      0.27      0.35        64\n",
      "    positive       0.68      0.89      0.77       139\n",
      "\n",
      "    accuracy                           0.66       264\n",
      "   macro avg       0.63      0.57      0.58       264\n",
      "weighted avg       0.64      0.66      0.63       264\n",
      "\n",
      "\n",
      "[[ 20   3  38]\n",
      " [  7   7  50]\n",
      " [  6   3 130]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.33      0.43        61\n",
      "     neutral       0.54      0.11      0.18        64\n",
      "    positive       0.60      0.94      0.73       139\n",
      "\n",
      "    accuracy                           0.59       264\n",
      "   macro avg       0.58      0.46      0.45       264\n",
      "weighted avg       0.58      0.59      0.53       264\n",
      "\n",
      "\n",
      "[[ 34  10  17]\n",
      " [ 15  28  21]\n",
      " [ 10  20 109]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.56      0.57        61\n",
      "     neutral       0.48      0.44      0.46        64\n",
      "    positive       0.74      0.78      0.76       139\n",
      "\n",
      "    accuracy                           0.65       264\n",
      "   macro avg       0.60      0.59      0.60       264\n",
      "weighted avg       0.64      0.65      0.64       264\n",
      "\n",
      "[17:26:00] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fergalflattery/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 30  11  20]\n",
      " [ 15  24  25]\n",
      " [ 12  18 109]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.53      0.49      0.51        61\n",
      "     neutral       0.45      0.38      0.41        64\n",
      "    positive       0.71      0.78      0.74       139\n",
      "\n",
      "    accuracy                           0.62       264\n",
      "   macro avg       0.56      0.55      0.55       264\n",
      "weighted avg       0.60      0.62      0.61       264\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, indices_train, indices_test, tf_vector = create_train_test(tweets_corpus, \"polarity\", 'lemma_clean_text', custom_stop_words)\n",
    "\n",
    "model_svc, y_predict_svc= train_model(SVC(kernel=\"linear\", tol=1e-7, C=.9),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_rbf, y_predict_rbf = train_model(SVC(kernel=\"rbf\", tol=1e-7, C=.9),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_nb, y_predict_nb = train_model(MultinomialNB(alpha= 0.5),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_LR, y_predict_LR = train_model(LogisticRegression(solver='lbfgs'),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_RF, y_predict_RF = train_model(RandomForestClassifier(max_depth= 14, max_features= 'sqrt',n_estimators= 10),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_GB, y_predict_GB = train_model(GradientBoostingClassifier(max_depth= 14, n_estimators= 500),\n",
    "                                       X_train, X_test, y_train, y_test)\n",
    "\n",
    "model_XG, y_predict_XG = train_model(XGBClassifier(eta= 1, gamma= 1, reg_lambda = 5, \n",
    "                                                           max_depth= 12, n_estimators= 500),\n",
    "                                       X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "738b7653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the models.\n",
    "path_model = \"\"\n",
    "\n",
    "with open(path_model + 'model_svc', 'wb') as picklefile:\n",
    "    pickle.dump(model_svc, picklefile)\n",
    "\n",
    "with open(path_model + 'model_rbf', 'wb') as picklefile:\n",
    "    pickle.dump(model_rbf,picklefile)\n",
    "\n",
    "with open(path_model + 'model_nb', 'wb') as picklefile:\n",
    "    pickle.dump(model_nb,picklefile)\n",
    "\n",
    "with open(path_model + 'model_LR', 'wb') as picklefile:\n",
    "    pickle.dump(model_LR,picklefile)\n",
    "\n",
    "with open(path_model + 'model_RF', 'wb') as picklefile:\n",
    "    pickle.dump(model_RF,picklefile)\n",
    "    \n",
    "with open(path_model + 'model_GB', 'wb') as picklefile:\n",
    "    pickle.dump(model_GB,picklefile)\n",
    "\n",
    "with open(path_model + 'model_XG', 'wb') as picklefile:\n",
    "    pickle.dump(model_XG,picklefile)\n",
    "\n",
    "with open(path_model + 'vectorizer.pk', 'wb') as fin:\n",
    "     pickle.dump(tf_vector, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "658f2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalysis:\n",
    "    \n",
    "    #path_model = \"/Users/fergalflattery/OneDrive - Athlone Institute Of Technology/ML & NN/\"\n",
    "    with open('model_rbf', 'rb') as training_model:\n",
    "        model_rbf = pickle.load(training_model)\n",
    "\n",
    "#    with open(path_model + 'model_rbf', 'rb') as training_model:\n",
    "#        model_rbf_pos = pickle.load(training_model)\n",
    "#\n",
    "    with open('vectorizer.pk', 'rb') as fin:\n",
    "        tf_vector = pickle.load(fin)\n",
    "    \n",
    "    def create_custom_stop_words(self, list_new_stopwords, remove_words):\n",
    "        custom_stop_words = list(set(stopwords.words('english')))\n",
    "        custom_stop_words.extend(list_new_stopwords)\n",
    "        custom_stop_words = [word for word in custom_stop_words if word not in remove_words]\n",
    "        return custom_stop_words\n",
    "\n",
    "    def lemmatizer(self, text,nlp):\n",
    "        sent = []\n",
    "        doc = nlp(text)\n",
    "        for word in doc:\n",
    "            sent.append(word.lemma_)\n",
    "        return \" \".join(sent)\n",
    "\n",
    "    def clean_text(self, s):\n",
    "        filters = [gsp.strip_tags,\n",
    "                   gsp.strip_punctuation,\n",
    "                   gsp.strip_multiple_whitespaces,\n",
    "                   gsp.strip_numeric]\n",
    "        s = re.sub(r'http\\S+', '', s)\n",
    "        s = s.lower()\n",
    "        s = utils.to_unicode(s)\n",
    "        s = utils.deaccent(s)\n",
    "        for f in filters:\n",
    "            s = f(s)\n",
    "        return s\n",
    "    \n",
    "    def preprocess(self, text, list_new_stopwords, remove_words, nlp):\n",
    "        custom_stop_words = self.create_custom_stop_words(list_new_stopwords, remove_words)\n",
    "        text = ' '.join([word for word in text.split() if word not in (custom_stop_words)])\n",
    "        text = self.clean_text(text)\n",
    "        text = self.lemmatizer(text, nlp)\n",
    "        return text\n",
    "    \n",
    "    def get_sentiment(self, text, model= model_rbf, vector= tf_vector):\n",
    "        stopwords_nltk = set(stopwords.words('english'))\n",
    "        exclude = set(string.punctuation)\n",
    "        lemma = WordNetLemmatizer()\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        #nlp.add_pipe(lemmatize, after=\"tagger\")\n",
    "\n",
    "        list_new_stopwords = [\"yet\", \"be\", \"watch\", \"today\", \"your\", \"here\",\n",
    "                              \"we go\", \"to have\", \"do\", \"have\", \"to go\",\n",
    "                                      \"say\", \"eat\",\"so\", \"well\"]\n",
    "        remove_words = [\"no\", \"yes\"]\n",
    "        text = self.preprocess(text, list_new_stopwords, remove_words, nlp)\n",
    "        \n",
    "        X_new = vector.transform([text])\n",
    "\n",
    "        predict_rbf = model.predict(X_new)\n",
    "#       predict_rbf_pos = model_pos.predict(X_new)\n",
    "\n",
    "        pred = \"\"\n",
    "        if (predict_rbf[0]== 'positive'): \n",
    "            pred = \"positive\"\n",
    "        elif (predict_rbf[0]== 'negative'): \n",
    "            pred = \"negative\"\n",
    "        elif (predict_rbf[0]== 'neutral'):\n",
    "            pred = \"neutral\"\n",
    "        return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14e93b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>lemma_clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Another class show tonight #TommyTiernanShow U...</td>\n",
       "      <td>positive</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:57:06+00:00</td>\n",
       "      <td>another class show tonight tommytiernanshow un...</td>\n",
       "      <td>another class show tonight tommytiernanshow un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The county needs more people like Tommy and Br...</td>\n",
       "      <td>positive</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:55:45+00:00</td>\n",
       "      <td>the county needs people like tommy brush tommy...</td>\n",
       "      <td>the county need people like tommy brush tommyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What age are ya????\\nHave you ever been examin...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:47:26+00:00</td>\n",
       "      <td>what age ya have ever examined simple question...</td>\n",
       "      <td>what age ya have ever examine simple question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tommy was almost as good as Croker earlier #Go...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:46:54+00:00</td>\n",
       "      <td>tommy almost good croker earlier goodsaturday ...</td>\n",
       "      <td>tommy almost good croker early goodsaturday to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#TommyTiernanShow Brush Shields walks out and ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-12 23:46:12+00:00</td>\n",
       "      <td>tommytiernanshow brush shields walks i self c...</td>\n",
       "      <td>tommytiernanshow brush shields walk i self c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>The line-up for this Friday's episode of the L...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-24 13:00:01+00:00</td>\n",
       "      <td>the line up friday s episode late late show re...</td>\n",
       "      <td>the line up friday s episode late late show re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>Friday night's show will be jam-packed with gu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-24 12:00:01+00:00</td>\n",
       "      <td>friday night s show jam packed guests host rya...</td>\n",
       "      <td>friday night s show jam pack guest host ryan t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>Comedian Patrick Kielty leads lineup for this ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-24 10:47:10+00:00</td>\n",
       "      <td>comedian patrick kielty leads lineup week s la...</td>\n",
       "      <td>comedian patrick kielty lead lineup week s lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>Will you be tuning in? #latelate #latelateshow...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-24 09:46:08+00:00</td>\n",
       "      <td>will tuning in latelate latelateshow</td>\n",
       "      <td>will tune in latelate latelateshow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>Here's the lineup for this week's #LateLateSho...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-02-24 09:35:41+00:00</td>\n",
       "      <td>here s lineup week s latelateshow</td>\n",
       "      <td>here s lineup week s latelateshow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1317 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  polarity  \\\n",
       "0     Another class show tonight #TommyTiernanShow U...  positive   \n",
       "1     The county needs more people like Tommy and Br...  positive   \n",
       "2     What age are ya????\\nHave you ever been examin...  positive   \n",
       "3     Tommy was almost as good as Croker earlier #Go...  positive   \n",
       "4     #TommyTiernanShow Brush Shields walks out and ...   neutral   \n",
       "...                                                 ...       ...   \n",
       "1312  The line-up for this Friday's episode of the L...   neutral   \n",
       "1313  Friday night's show will be jam-packed with gu...  positive   \n",
       "1314  Comedian Patrick Kielty leads lineup for this ...  positive   \n",
       "1315  Will you be tuning in? #latelate #latelateshow...   neutral   \n",
       "1316  Here's the lineup for this week's #LateLateSho...   neutral   \n",
       "\n",
       "      favourite_count  retweet_count                 created_at  \\\n",
       "0                   5              0  2022-02-12 23:57:06+00:00   \n",
       "1                   6              0  2022-02-12 23:55:45+00:00   \n",
       "2                   1              0  2022-02-12 23:47:26+00:00   \n",
       "3                   1              0  2022-02-12 23:46:54+00:00   \n",
       "4                   2              0  2022-02-12 23:46:12+00:00   \n",
       "...               ...            ...                        ...   \n",
       "1312                0              0  2022-02-24 13:00:01+00:00   \n",
       "1313                2              0  2022-02-24 12:00:01+00:00   \n",
       "1314                0              0  2022-02-24 10:47:10+00:00   \n",
       "1315                2              0  2022-02-24 09:46:08+00:00   \n",
       "1316                2              0  2022-02-24 09:35:41+00:00   \n",
       "\n",
       "                                          content_clean  \\\n",
       "0     another class show tonight tommytiernanshow un...   \n",
       "1     the county needs people like tommy brush tommy...   \n",
       "2     what age ya have ever examined simple question...   \n",
       "3     tommy almost good croker earlier goodsaturday ...   \n",
       "4      tommytiernanshow brush shields walks i self c...   \n",
       "...                                                 ...   \n",
       "1312  the line up friday s episode late late show re...   \n",
       "1313  friday night s show jam packed guests host rya...   \n",
       "1314  comedian patrick kielty leads lineup week s la...   \n",
       "1315              will tuning in latelate latelateshow    \n",
       "1316                 here s lineup week s latelateshow    \n",
       "\n",
       "                                       lemma_clean_text  \n",
       "0     another class show tonight tommytiernanshow un...  \n",
       "1     the county need people like tommy brush tommyt...  \n",
       "2     what age ya have ever examine simple question ...  \n",
       "3     tommy almost good croker early goodsaturday to...  \n",
       "4       tommytiernanshow brush shields walk i self c...  \n",
       "...                                                 ...  \n",
       "1312  the line up friday s episode late late show re...  \n",
       "1313  friday night s show jam pack guest host ryan t...  \n",
       "1314  comedian patrick kielty lead lineup week s lat...  \n",
       "1315                 will tune in latelate latelateshow  \n",
       "1316                  here s lineup week s latelateshow  \n",
       "\n",
       "[1317 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d739a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebd857e5",
   "metadata": {},
   "source": [
    "New tweets - test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a19b8346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = SentimentAnalysis()\n",
    "text = \"that sports game was awful\"\n",
    "sentiment.get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8af90d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = SentimentAnalysis()\n",
    "text = \"the late late show was so bad tonight i hate the presenter \"\n",
    "sentiment.get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88342285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = SentimentAnalysis()\n",
    "text = \"what a dreadful show that was.\"\n",
    "sentiment.get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c15346d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = SentimentAnalysis()\n",
    "text = \"that was great\"\n",
    "sentiment.get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3afdb85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = SentimentAnalysis()\n",
    "text = \"i dont know whether to be happy or sad\"\n",
    "sentiment.get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de95ef01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = SentimentAnalysis()\n",
    "text = \"load of rubbush\"\n",
    "sentiment.get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97299c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = SentimentAnalysis()\n",
    "text = \"i dont understand the person talking\"\n",
    "sentiment.get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8372e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = SentimentAnalysis()\n",
    "text = \"tl\"\n",
    "sentiment.get_sentiment(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
